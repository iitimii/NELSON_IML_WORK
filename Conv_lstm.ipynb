{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset  # Gives easier dataset managment by creating mini batches etc.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, f1_score, recall_score, precision_score\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data from the files\n",
    "#read the data \n",
    "#algorithm to read all the files \n",
    "\n",
    "'''\n",
    "for folder in this folder:\n",
    "    read xelasensor1.csv\n",
    "    read sliplabel.csv\n",
    "    concat it in a single dataframe along axis = 0\n",
    "\n",
    "print the dataframe\n",
    "'''\n",
    "\n",
    "directory = '/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/train2dof'\n",
    "directory2 = '/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/'\n",
    "\n",
    "def read_file(detect_or_pred, n = None):\n",
    "\n",
    "    #store all directories in a list\n",
    "    list_xela_allfiles = []\n",
    "    list_sliplabel_allfiles = []\n",
    "\n",
    "    for root, subdirectories, files in os.walk(directory):\n",
    "        for sdirectory in subdirectories:\n",
    "\n",
    "            #subdirectory with absolute path\n",
    "            subdirectory = '{}/{}'.format(root, sdirectory)\n",
    "\n",
    "            #read specific files in the subdirectory\n",
    "            for file in os.listdir(subdirectory):\n",
    "            \n",
    "                if file.endswith(\"sensor1.csv\"):\n",
    "                    df = pd.read_csv('{}/{}'.format(subdirectory, file), index_col=None, header=0)\n",
    "                    \n",
    "                    if detect_or_pred ==0:\n",
    "                        list_xela_allfiles.append(df)\n",
    "                    elif detect_or_pred ==1 and n is not None:\n",
    "                        list_xela_allfiles.append(df[:-n])\n",
    "\n",
    "                if file.endswith(\"label.csv\"):\n",
    "                    df = pd.read_csv('{}/{}'.format(subdirectory, file), index_col=None, header=0)\n",
    "                    if detect_or_pred ==0:\n",
    "                        list_sliplabel_allfiles.append(df)\n",
    "                    elif detect_or_pred ==1 and n is not None: \n",
    "                        list_sliplabel_allfiles.append(df[n:])\n",
    "\n",
    "    return list_xela_allfiles, list_sliplabel_allfiles\n",
    "\n",
    "    #np.newaxis; np.zeros (3,4,4) -> \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the list of xela_allfiles and sliplabel_allfiles across axis = 0\n",
    "n = 5\n",
    "list_xela_allfiles, list_sliplabel_allfiles = read_file(0)\n",
    "\n",
    "#for slip prediction, comment the line above and uncomment the line below\n",
    "#list_xela_allfiles, list_sliplabel_allfiles = read_file(1, n)\n",
    "\n",
    "pd_xela_allfiles = pd.concat(list_xela_allfiles, axis=0, ignore_index=True)\n",
    "pd_sliplabel_allfiles = pd.concat(list_sliplabel_allfiles, axis=0, ignore_index=True)\n",
    "pd_sliplabel_allfiles = pd_sliplabel_allfiles['slip']\n",
    "\n",
    "#reshape the target array into (rows, 1)\n",
    "#tac_label \n",
    "pd_sliplabel_allfiles = pd_sliplabel_allfiles.values.reshape(pd_sliplabel_allfiles.shape[0], 1)\n",
    "tac_label = pd_sliplabel_allfiles\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "data = pd_xela_allfiles.to_numpy()\n",
    "data = sc.fit_transform(data)\n",
    "labels = pd_sliplabel_allfiles\n",
    "(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(labels)\n",
    "df.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONV LSTM "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrange the data to form images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrange the 48 row data to form 3, 4, 4\n",
    "\n",
    "#arrange the columns by x, y, z\n",
    "col_x = []\n",
    "col_y = []\n",
    "col_z = []\n",
    "\n",
    "pd_columns = pd_xela_allfiles.columns\n",
    "for col in pd_columns:\n",
    "    if col.endswith('x'):\n",
    "        col_x.append(col)\n",
    "    \n",
    "    elif col.endswith('y'):\n",
    "        col_y.append(col)\n",
    "    \n",
    "    elif col.endswith('z'):\n",
    "        col_z.append(col)\n",
    "\n",
    "#arrange the table using the arranged columns\n",
    "pd_xela_allfiles_x = pd_xela_allfiles[col_x]\n",
    "pd_xela_allfiles_y = pd_xela_allfiles[col_y]\n",
    "pd_xela_allfiles_z = pd_xela_allfiles[col_z]\n",
    "\n",
    "\n",
    "#scale the data in the arranged columns\n",
    "#scale the data of the features\n",
    "\n",
    "sc = MinMaxScaler() #standard scaler\n",
    "sc.fit(pd_xela_allfiles_x)\n",
    "pd_xela_allfiles_x = sc.transform(pd_xela_allfiles_x)\n",
    "\n",
    "sc.fit(pd_xela_allfiles_y)\n",
    "pd_xela_allfiles_y = sc.transform(pd_xela_allfiles_y)\n",
    "\n",
    "sc.fit(pd_xela_allfiles_z)\n",
    "pd_xela_allfiles_z = sc.transform(pd_xela_allfiles_z)\n",
    "\n",
    "\n",
    "\n",
    "#reshape the arranged data per row to (4,4) AND rotate 90 degree anti-clockwise and append to a list\n",
    "pd_x = []\n",
    "pd_y = []\n",
    "pd_z = []\n",
    "\n",
    "for row in range(len(pd_xela_allfiles_x)):\n",
    "    pd_x.append(np.rot90(pd_xela_allfiles_x[row].reshape(4,4)))\n",
    "    pd_y.append(np.rot90(pd_xela_allfiles_y[row].reshape(4,4)))\n",
    "    pd_z.append(np.rot90(pd_xela_allfiles_z[row].reshape(4,4)))\n",
    "\n",
    "#add all the x, y, z in a single list\n",
    "pd_main = [pd_x, pd_y, pd_z]\n",
    "\n",
    "#arrange pd_main in a 3, 4, 4 array where its 3(4, 4) of x, y, z values\n",
    "pd_image = np.zeros( (pd_xela_allfiles.shape[0], 3, 4, 4))\n",
    "\n",
    "#per row, get (4,4) of x, y, z and assign it to pd_image to form the image\n",
    "for row in range(pd_xela_allfiles.shape[0]):\n",
    "    x_4_4 = pd_main[0][row]\n",
    "    y_4_4 = pd_main[1][row]\n",
    "    z_4_4 = pd_main[2][row]\n",
    "\n",
    "    pd_image[row][0] = x_4_4\n",
    "    pd_image[row][1] = y_4_4\n",
    "    pd_image[row][2] = z_4_4\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upscale the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale the image, Train, Get the shape, Form my dense layer\n",
    "\n",
    "#Upscale the (4,4) part of the 3, 4, 4 image to 16, 16, 16,\n",
    "import cv2\n",
    "\n",
    "up_size = 64\n",
    "n_images = len(pd_x)\n",
    "tac_image = np.zeros((n_images, 3, up_size, up_size), np.float32) \n",
    "for row in range(n_images):\n",
    "\n",
    "    #resize image to 3, up_size, up_size\n",
    "    for channel in range(3):\n",
    "        image_per_channel = pd_image[row][channel]\n",
    "        tac_image[row][channel] = cv2.resize(image_per_channel.astype(np.float32), dsize=(up_size, up_size), interpolation=cv2.INTER_CUBIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scaled image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "''' X = tac_image[199000][0]\n",
    "Y = tac_image[199000][1]\n",
    "Z = tac_image[199000][2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(X, Y, Z, linewidth=0,\n",
    "       cstride = 1, rstride = 1)\n",
    "plt.show() '''\n",
    "\n",
    "# see also\n",
    "plt.imshow(tac_image[0][1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensor values\n",
    "tac_image = torch.from_numpy(tac_image.astype(np.float32))\n",
    "tac_label = torch.from_numpy(tac_label.astype(np.float32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design the ConvLSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Validation split\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(tac_image, tac_label, test_size = 0.25, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq_dataset(Dataset):\n",
    "    def __init__(self, X, y, seq_len):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.seq_len = seq_len\n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - (self.seq_len-1)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index:index+self.seq_len], self.y[index+self.seq_len-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_dataset = seq_dataset(data_train, labels_train, 10)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "val_dataset = seq_dataset(data_test, labels_test, 10)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias, device):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim, out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size, padding=self.padding, bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o) \n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device).to(self.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device).to(self.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Model, self).__init__()\n",
    "        self.device = device\n",
    "        self.convlstm1 = ConvLSTMCell(input_dim=3, hidden_dim=3, kernel_size=(3, 3), bias=True, device=self.device).to(self.device)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1).to(self.device)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1).to(self.device)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1).to(self.device)\n",
    "        self.maxpool1 = nn.MaxPool2d(4, stride=4)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.maxpool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.relu1 = nn.ReLU().to(self.device)\n",
    "        self.relu2 = nn.ReLU().to(self.device)\n",
    "        self.relu3 = nn.ReLU().to(self.device)\n",
    "        self.dense1 = nn.Linear(256, 64).to(self.device)\n",
    "        self.dense2 = nn.Linear(64, 32).to(self.device)\n",
    "        self.dense3 = nn.Linear(32, 1).to(self.device)\n",
    "        self.relu4 = nn.ReLU().to(self.device)\n",
    "        self.relu5 = nn.ReLU().to(self.device)\n",
    "        self.flatten = nn.Flatten().to(self.device)\n",
    "        self.sigmoid = nn.Sigmoid().to(self.device)\n",
    "        # self.optimizer = optim.Adam(Model.parameters(), lr=0.0001)\n",
    "        # self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self,X):\n",
    "        hidden, cell = self.convlstm1.init_hidden(batch_size=batch_size, image_size=(64, 64))\n",
    "        for t in range(10):\n",
    "            hidden, cell = self.convlstm1(input_tensor=X[:,t,:,:,:], cur_state=[hidden, cell])\n",
    "        x = self.maxpool1(self.relu1(self.conv1(hidden).float()))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x).float()))\n",
    "        x = self.maxpool3(self.relu3(self.conv3(x).float()))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu4(self.dense1(x).float())\n",
    "        x = self.relu5(self.dense2(x).float())\n",
    "        out = self.sigmoid(self.dense3(x).float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = Model(device)\n",
    "model.load_state_dict(torch.load(\"CONV_LSTM_working.pth\"))\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "weight = torch.Tensor([5])\n",
    "criterion = nn.BCELoss(weight=weight)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "loss_per_batch = []\n",
    "loss_per_epoch= []\n",
    "loss_per_epoch_val = []\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "t_acc = []\n",
    "v_acc = []\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss = []   \n",
    "    train_acc = []  \n",
    "    t_correct = 0                                            \n",
    "    model.train()                                                  \n",
    "    for batch_num, (input, target) in enumerate(train_loader, 1): \n",
    "        print(f'Batch: {batch_num}')                              \n",
    "        optim.zero_grad()  \n",
    "        output = model(input) \n",
    "        loss = criterion(output.flatten(), target.flatten()) \n",
    "        #loss_per_batch.append(loss.item())  \n",
    "        loss.backward()                                            \n",
    "        optim.step()                                             \n",
    "        train_loss.append(loss.item())                             \n",
    "    #train_loss /= len(train_loader.dataset) \n",
    "    #loss_per_epoch.append(train_loss)\n",
    "\n",
    "    #accuracy\n",
    "        t_correct += output.round().eq(target).sum().item()\n",
    "        train_acc.append(t_correct/target.shape[0])\n",
    "\n",
    "    val_loss = []  \n",
    "    val_acc = []  \n",
    "    v_correct = 0                                            \n",
    "    model.eval()                                                   \n",
    "    with torch.no_grad():                                          \n",
    "        for batch_num, (input, target) in enumerate(val_loader, 1):   \n",
    "            print(f'Validation Batch: {batch_num}')          \n",
    "            output = model(input)                                   \n",
    "            loss = criterion(output.flatten(), target.flatten())   \n",
    "            val_loss.append(loss.item())   \n",
    "\n",
    "            v_correct += output.round().eq(target).sum().item()\n",
    "            val_acc.append(v_correct/target.shape[0])                           \n",
    "    #val_loss /= len(val_loader.dataset)  \n",
    "    #loss_per_epoch_val.append(val_loss)  \n",
    "\n",
    "    t_loss.append(np.mean(train_loss))\n",
    "    v_loss.append(np.mean(val_loss))\n",
    "    t_acc.append(np.mean(train_acc))     \n",
    "    v_acc.append(np.mean(val_acc))                        \n",
    "\n",
    "    print(\"Epoch:{} Training Loss:{:.2f} Validation Loss:{:.2f} Training Acc:{:.2f} Validation Acc:{:.2f}\\n\"\\\n",
    "          .format(epoch, (np.mean(train_loss)), np.mean(val_loss), (np.mean(train_acc)), np.mean(val_acc)))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(v_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_metrics(xela_test, sliplabel_test):\n",
    "    #predict using the holdout set (DONE)\n",
    "    predicted_cls = xela_test\n",
    "\n",
    "    #Plot the loss values against number of epochs (DONE)\n",
    "    #validation test (DONE)\n",
    "\n",
    "    #Print the accuracy\n",
    "    x = 0\n",
    "    for i in range(predicted_cls.shape[0]):\n",
    "        if predicted_cls[i, 0].item() == sliplabel_test[i, 0]:\n",
    "            x += 1\n",
    "\n",
    "    accuracy = x/ float(sliplabel_test.shape[0])\n",
    "    # print(f'Accuracy for slip detection is {accuracy}')\n",
    "\n",
    "    #Print the fscore\n",
    "    fscore = f1_score(sliplabel_test, predicted_cls, average='macro')\n",
    "    # print (f'Fscore for slip detection is {fscore}')\n",
    "\n",
    "    #print the Precision\n",
    "    precision = precision_score(sliplabel_test, predicted_cls, average='macro')\n",
    "    # print(f'Precision for slip detection is {precision}')\n",
    "\n",
    "    #print the Recall\n",
    "    recall = recall_score(sliplabel_test, predicted_cls, average='macro')\n",
    "    # print(f'Recall for slip detection is {recall}')\n",
    "\n",
    "    return accuracy, fscore, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = Model(device)\n",
    "model.load_state_dict(torch.load(\"CONV_LSTM_working.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_PRED = []\n",
    "Y_VAL = []\n",
    "ACC = []\n",
    "FSCORE = []\n",
    "RECALL = []\n",
    "PRECISION = []\n",
    "x=0\n",
    "for (i,t) in val_loader:\n",
    "    x+=1\n",
    "    y_predict = model.forward(i)\n",
    "    y_predict = y_predict.round()\n",
    "    y_predict = y_predict.data.numpy()\n",
    "    # y_predict = y_predict.flatten()\n",
    "    y_valid = t#.flatten()\n",
    "    accuracy, fscore, precision, recall = lstm_metrics(y_predict, y_valid)\n",
    "    ACC.append(accuracy)\n",
    "    FSCORE.append(fscore)\n",
    "    PRECISION.append(precision)\n",
    "    RECALL.append(recall)\n",
    "    print(f'{x} / {len(val_loader)}')\n",
    "\n",
    "# y_predict = [model.forward(i) for i,t in val_loader]\n",
    "# y_valid = [t for i,t in val_loader]\n",
    "# y_predict = torch.Tensor(y_predict)\n",
    "# y_valid = torch.Tensor(y_valid)\n",
    "# print(y_predict.shape)\n",
    "# y_predict = y_predict.flatten()\n",
    "# y_valid = y_valid.flatten()\n",
    "# y_predict = y_predict.round()\n",
    "# y_predict = y_predict.data.numpy()\n",
    "# y_valid = y_valid\n",
    "# lstm_metrics(y_predict, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean(ACC)\n",
    "fscore = np.mean(FSCORE)\n",
    "precision = np.mean(PRECISION)\n",
    "recall = np.mean(RECALL)\n",
    "\n",
    "print(f'Accuracy: {accuracy}, Fscore: {fscore}, Recall: {recall}, Precision: {precision}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "173c0cb41f479ae2d1f90bf66f9ae3aceca0c8feada6413b4ebace4131a19a6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
